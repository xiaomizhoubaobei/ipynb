{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### 版权所有 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title 根据 Apache 许可证 2.0 版本（“许可证”）授权；\n",
        "# 除非遵循许可证，否则不得使用本文件。\n",
        "# 您可以通过以下地址获取许可证副本：\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# 除非适用法律要求或书面同意，\n",
        "# 否则根据“现状”分发本软件，不附带任何明示或暗示的保证。\n",
        "# 详见许可证中关于权限与限制的具体条款。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfsDR_omdNea"
      },
      "source": [
        "# CodeGemma - 常见用例\n",
        "本笔记本通过合适的提示（prompting）展示 Gemma 能够解决的基础任务。\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/gemma-cookbook/blob/main/CodeGemma/[CodeGemma_1]Common_use_cases.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />在 Google Colab 运行</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9sUQ4WrP-Yr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# 我这里使用的配置文件直接导入为环境变量\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"你的kaggle用户名\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"你的kaggle key\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwjo5_Uucxkw"
      },
      "source": [
        "### 安装依赖\n",
        "运行下方单元格，安装所有必需的依赖包。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_nXPEsF7UWQ"
      },
      "outputs": [],
      "source": [
        "%pip install -q -U keras keras-nlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOAEiJmnBE0D"
      },
      "source": [
        "## 探索提示能力"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CIQwvFT4IgN"
      },
      "source": [
        "### CodeGemma\n",
        "\n",
        "CodeGemma 模型是“文本到文本”以及“文本到代码”的纯解码器模型，专门用于代码补全与代码生成任务。CodeGemma 2B 与 7B 版本特别针对**代码填充（infilling）**场景进行了调优。\n",
        "\n",
        "本示例利用 CodeGemma 的 **FIM（Fill-in-the-middle）** 能力，根据上下文自动补全代码。这在代码编辑器中尤为实用：当光标位于某段代码中间时，模型可根据前后文自动插入缺失内容。\n",
        "\n",
        "CodeGemma 提供 4 个用户自定义标记：\n",
        "- `<|fim_prefix|>`\n",
        "- `<|fim_suffix|>`\n",
        "- `<|fim_middle|>`\n",
        "- `<|file_separator|>`（用于多文件上下文）\n",
        "\n",
        "接下来我们将用这些标记定义常量，并在后续单元格中演示具体用法。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTug97S93rs8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras\n",
        "import keras_nlp\n",
        "from google.colab import userdata\n",
        "\n",
        "keras.config.set_floatx(\"bfloat16\")\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get(\"KAGGLE_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq_ZwkLQlYgt"
      },
      "outputs": [],
      "source": [
        "# 加载 CodeGemma\n",
        "codegemma = keras_nlp.models.GemmaCausalLM.from_preset(\"code_gemma_1.1_2b_en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOQZppz2OI4-"
      },
      "outputs": [],
      "source": [
        "# 定义标记常量\n",
        "BEFORE_CURSOR = \"<|fim_prefix|>\"\n",
        "AFTER_CURSOR = \"<|fim_suffix|>\"\n",
        "AT_CURSOR = \"<|fim_middle|>\"\n",
        "FILE_SEPARATOR = \"<|file_separator|>\"\n",
        "END_TOKEN = codegemma.preprocessor.tokenizer.end_token\n",
        "stop_tokens = (BEFORE_CURSOR, AFTER_CURSOR, AT_CURSOR, FILE_SEPARATOR, END_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7yYzlwSOPym"
      },
      "outputs": [],
      "source": [
        "stop_token_ids = tuple(\n",
        "    codegemma.preprocessor.tokenizer.token_to_id(x) for x in stop_tokens\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SciCjeWQB1Jm"
      },
      "source": [
        "#### 提示示例：代码填充"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtTQAJKUSEZ5"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# 辅助函数\n",
        "def split_response_by_token(response):\n",
        "    mapping = {}\n",
        "    parts = re.split(r\"(<\\|[^\\|\\>]+\\|\\>)\", response)\n",
        "    parts = [item for item in parts if len(item)]\n",
        "    for token in stop_tokens[:3]:\n",
        "        mapping[token] = \"\"\n",
        "\n",
        "        try:\n",
        "            idx = parts.index(token)\n",
        "            if parts[idx + 1] not in stop_tokens:\n",
        "                mapping[token] = parts[idx + 1]\n",
        "        except (ValueError, IndexError):\n",
        "            pass\n",
        "\n",
        "    return mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDozO7l3hkGt"
      },
      "outputs": [],
      "source": [
        "prefix = \"def calculate_area_of_rectangle(a: int, b: int) -> int:\"\n",
        "suffix = \"\\n    return area\"\n",
        "prompt = f\"<|fim_prefix|>{prefix}<|fim_suffix|>{suffix}<|fim_middle|>\"\n",
        "\n",
        "response = codegemma.generate(prompt, stop_token_ids=stop_token_ids)\n",
        "parts = split_response_by_token(response)\n",
        "\n",
        "print(\"--- 原始响应 ---\")\n",
        "print(response)\n",
        "\n",
        "print(\"\\n--- 生成的（FIM）代码片段： ---\")\n",
        "print(parts[AT_CURSOR])\n",
        "\n",
        "print(\"\\n--- 完整函数： ---\")\n",
        "print(parts[BEFORE_CURSOR], parts[AT_CURSOR], parts[AFTER_CURSOR])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebBqyJDjB32U"
      },
      "source": [
        "#### 提示示例：代码生成\n",
        "_注意：虽然 2B 版 CodeGemma 主要面向代码补全场景，但它也能完成基础代码生成任务。如需更佳的代码生成效果，建议使用经过指令调优的 7B 模型。_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaxpsXjbgYSs"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"用一行 Python 代码判断某年是否为闰年。\n",
        "示例：\n",
        ">>> is_a_leap_year(2016)\n",
        "True\n",
        ">>> is_a_leap_year(2001)\n",
        "False\n",
        ">>> is_a_leap_year(2052)\n",
        "True\n",
        "def is_a_leap_year(year: int) -> bool:\"\"\"\n",
        "\n",
        "response = codegemma.generate(prompt, max_length=128)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFVNs_PHOivu"
      },
      "outputs": [],
      "source": [
        "# 需要重启会话以释放 GPU 内存，并加载新模型\n",
        "get_ipython().kernel.do_shutdown(True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[CodeGemma_1]常见用例.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
